<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; A review of linear models – MPS318/4101 Sampling Theory and Design of Experiments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Optimality.html" rel="next">
<link href="./Introduction to experimental design.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Introduction to experimental design.html">Part I: Experimental Design</a></li><li class="breadcrumb-item"><a href="./Review of linear models.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A review of linear models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MPS318/4101 Sampling Theory and Design of Experiments</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instructions</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Experimental Design</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Introduction to experimental design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Experimental Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Review of linear models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A review of linear models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Optimality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Optimality criteria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Qualitative-single factor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Qualitative explanatory variables and blocking</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Qualitative-multiple factors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Latin Square designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Factorial designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Factorial designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Continuous and exact designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous and exact designs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Sampling Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Introduction to sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Simple random sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Simple Random Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Sample sizes and confidence intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Confidence intervals and sample sizes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Stratified sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Stratified Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Population size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Estimating a Population Size</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Practicalities.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Reliability of sample surveys</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: self-study topics for MPS4101</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Tailor-made designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Modifying designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cluster sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Cluster Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Introduction-computer-experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction to computer experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Uncertainty-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Uncertainty analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Sensitivity-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Sensitivity analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-general-linear-model" id="toc-the-general-linear-model" class="nav-link active" data-scroll-target="#the-general-linear-model"><span class="header-section-number">2.1</span> The general linear model</a></li>
  <li><a href="#matrix-notation" id="toc-matrix-notation" class="nav-link" data-scroll-target="#matrix-notation"><span class="header-section-number">2.2</span> Matrix notation</a>
  <ul class="collapse">
  <li><a href="#big-mathbfy-and-little-mathbfy-notation" id="toc-big-mathbfy-and-little-mathbfy-notation" class="nav-link" data-scroll-target="#big-mathbfy-and-little-mathbfy-notation"><span class="header-section-number">2.2.1</span> Big <span class="math inline">\(\mathbf{Y}\)</span> and little <span class="math inline">\(\mathbf{y}\)</span> notation</a></li>
  </ul></li>
  <li><a href="#least-squares-estimation" id="toc-least-squares-estimation" class="nav-link" data-scroll-target="#least-squares-estimation"><span class="header-section-number">2.3</span> Least squares estimation</a></li>
  <li><a href="#statistical-properties-of-the-least-squares-estimator" id="toc-statistical-properties-of-the-least-squares-estimator" class="nav-link" data-scroll-target="#statistical-properties-of-the-least-squares-estimator"><span class="header-section-number">2.4</span> Statistical properties of the least squares estimator</a></li>
  <li><a href="#estimating-the-error-variance-sigma2" id="toc-estimating-the-error-variance-sigma2" class="nav-link" data-scroll-target="#estimating-the-error-variance-sigma2"><span class="header-section-number">2.5</span> Estimating the error variance <span class="math inline">\(\sigma^2\)</span></a></li>
  <li><a href="#sec-qualvars" id="toc-sec-qualvars" class="nav-link" data-scroll-target="#sec-qualvars"><span class="header-section-number">2.6</span> Models with qualitative variables</a></li>
  <li><a href="#sec-orthogonality" id="toc-sec-orthogonality" class="nav-link" data-scroll-target="#sec-orthogonality"><span class="header-section-number">2.7</span> Orthogonality</a></li>
  <li><a href="#prediction" id="toc-prediction" class="nav-link" data-scroll-target="#prediction"><span class="header-section-number">2.8</span> Prediction</a></li>
  <li><a href="#sec-confregions" id="toc-sec-confregions" class="nav-link" data-scroll-target="#sec-confregions"><span class="header-section-number">2.9</span> Confidence regions</a></li>
  <li><a href="#tasks" id="toc-tasks" class="nav-link" data-scroll-target="#tasks"><span class="header-section-number">2.10</span> Tasks</a></li>
  <li><a href="#sec-ch2Appendix" id="toc-sec-ch2Appendix" class="nav-link" data-scroll-target="#sec-ch2Appendix"><span class="header-section-number">2.11</span> Appendix</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Introduction to experimental design.html">Part I: Experimental Design</a></li><li class="breadcrumb-item"><a href="./Review of linear models.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A review of linear models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-linmod" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">A review of linear models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>Aims for this chapter
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this module, we consider experimental design on the assumption that our data can be analysed with a linear model, and so we review linear model theory in this chapter. We consider in particular how the choice of experimental design relates to the accuracy of linear model parameter estimates and predictions obtained from linear models.</p>
</div>
</div>
<section id="the-general-linear-model" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-general-linear-model"><span class="header-section-number">2.1</span> The general linear model</h2>
<p>In this course, we shall mostly be concerned with the <strong>general linear model</strong> which takes the form <span class="math display">\[\begin{equation}
Y = \mathbf{f}(\mathbf{x})^T\boldsymbol{\beta}+\varepsilon=\sum_{i=1}^p f_i(\mathbf{x})\beta_i + \varepsilon,
\end{equation}\]</span> where <span class="math inline">\(\mathbf{f}(\mathbf{x})^T = (f_1(\mathbf{x}) ~~ f_2(\mathbf{x})~~\ldots ~~f_p(\mathbf{x})\)</span> is a row vector of known functions of <span class="math inline">\(\mathbf{x}\)</span>. <span class="math inline">\(\mathbf{x}= (x_1~~x_2~~\ldots ~~x_m)^T\)</span> is a vector of known explanatory variable values and <span class="math inline">\(\varepsilon\)</span> is a random variable with mean zero.</p>
<p>We assume that <span class="math inline">\(\varepsilon\)</span> is normally distributed, but the mean of <span class="math inline">\(\varepsilon\)</span> is zero by definition; constants are included in the term <span class="math inline">\(\mathbf{f}(\mathbf{x})^T\boldsymbol{\beta}\)</span> as needed.</p>
<p>When specifying a linear model, we may write <span class="math display">\[
Y = \mathbf{f}(\mathbf{x})^T\boldsymbol{\beta}+\varepsilon,
\]</span> or we may instead write <span class="math display">\[
E(Y) = \mathbf{f}(\mathbf{x})^T\boldsymbol{\beta}
\]</span></p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-linandquad" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.1</strong></span> The simple linear regression model may be written <span class="math display">\[Y = \beta_0 + \beta_1 x + \varepsilon\]</span> so that in this case <span class="math inline">\(m=1\)</span>, <span class="math inline">\(p=2\)</span>, <span class="math inline">\(\mathbf{x}=x\)</span> and <span class="math inline">\(\mathbf{f}(\mathbf{x})^T=(1~~x)\)</span>.</p>
<p>The quadratic regression model may be written <span class="math display">\[Y = \beta_0 + \beta_1 x + \beta_{11}x^2 + \varepsilon\]</span> so that in this case <span class="math inline">\(m=1\)</span>, <span class="math inline">\(p=3\)</span>, <span class="math inline">\(\mathbf{x}=x\)</span> and <span class="math inline">\(\mathbf{f}(\mathbf{x})^T = (1~~x~~x^2)\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Polynomial regression models are linear models!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Though the quadratic regression model above is not linear in <span class="math inline">\(x\)</span>, it is still classified as a linear model, because the <span class="math inline">\(E(Y)\)</span> is a linear combination of the <em>parameters</em> <span class="math inline">\(\beta_0,\beta_1,\ldots...\)</span>; it can be written in the matrix notation in the next section, and all the general linear model theory still applies. Hence linear models can describe complicated non-linear relationships between the explanatory variables and the response variable.</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-quadm4" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.2</strong></span> With <span class="math inline">\(m=4\)</span> a full quadratic model may be written <span class="math display">\[\begin{align}
Y &amp;= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_4x_4 + \beta_{12}x_1x_2 + \beta_{13}x_1x_3 + \beta_{14}x_1x_4 \\
&amp;+ \beta_{23}x_2x_3 + \beta_{24}x_2x_4 + \beta_{34}x_3x_4 + \beta_{11}x_1^2 + \beta_{22}x_2^2 + \beta_{33}x_3^2 + \beta_{44}x_4^2 + \varepsilon .
\end{align}\]</span> Note how in this example the <span class="math inline">\(\beta\)</span> parameters are labelled with subscripts reflecting the explanatory variables to which they are relevant, and in what way: this is a common convention.</p>
</div>
</div>
</div>
</section>
<section id="matrix-notation" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="matrix-notation"><span class="header-section-number">2.2</span> Matrix notation</h2>
<p>Suppose that our design consists of <span class="math inline">\(n\)</span> points <span class="math inline">\(\mathbf{x_1}, \mathbf{x_2},\ldots , \mathbf{x_n}\)</span> (some of which will be the same if replication occurs) and the corresponding observations are <span class="math inline">\(Y_1, Y_2, \ldots , Y_n\)</span>. Then we have <span class="math display">\[Y_j = \mathbf{f}(\mathbf{x_j})^T\boldsymbol{\beta}+\varepsilon_j \;\;\;\ \text{for} \;\;\;\ j=1,2,\ldots ,n\]</span> say, and these <span class="math inline">\(n\)</span> equations may be collected together into the single matrix equation <span class="math display">\[\mathbf{Y}= \mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon}\]</span> where <span class="math inline">\(\mathbf{Y}\)</span> and <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> are column vectors containing <span class="math inline">\(Y_1,Y_2, \ldots , Y_n\)</span> and <span class="math inline">\(\varepsilon_1, \varepsilon_2, \ldots ,\varepsilon_n\)</span> respectively, and <span class="math inline">\(\mathbf{X}\)</span> is the <span class="math inline">\(n\times p\)</span> matrix whose rows are <span class="math display">\[\mathbf{f}(\mathbf{x_1})^T, \mathbf{f}(\mathbf{x_2})^T, \ldots , \mathbf{f}(\mathbf{x_n})^T\]</span> respectively. This may also be written <span class="math display">\[E(\mathbf{Y})= \mathbf{X}\boldsymbol{\beta}.\]</span></p>
<p>The matrix <span class="math inline">\(\mathbf{X}\)</span> is known as the <strong>design matrix</strong> of the experiment. It should be noted, however, that it depends not only on the design as previously defined, but also on the model chosen, via the function <span class="math inline">\(\mathbf{f}\)</span>.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-2.2" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.3</strong></span> Suppose there is a single explanatory variable <span class="math inline">\(x\)</span> and it is decided to take one observation at each of the five points <span class="math inline">\(x=0,1,2,3\)</span> and <span class="math inline">\(4\)</span>. Then for the simple linear regression model the design matrix will be <span class="math display">\[\mathbf{X}=\left(\begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 2 \\ 1 &amp; 3 \\ 1 &amp; 4 \end{array} \right)\]</span> whereas for the quadratic regression model it will be <span class="math display">\[\mathbf{X}=\left(\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 2 &amp; 4 \\ 1 &amp; 3 &amp; 9 \\ 1 &amp; 4 &amp; 16 \end{array}\right).\]</span></p>
</div>
</div>
</div>
<p>Note that under the usual assumptions that <span class="math inline">\(\varepsilon_1, \varepsilon_2, \ldots ,\varepsilon_n\stackrel{i.i.d}{\sim}N(0,\sigma^2)\)</span>, we have</p>
<p><span class="math display">\[
\mathbf{Y}\sim N(\mathbf{X}\boldsymbol{\beta}, \sigma^2I_n)
\]</span></p>
<section id="big-mathbfy-and-little-mathbfy-notation" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="big-mathbfy-and-little-mathbfy-notation"><span class="header-section-number">2.2.1</span> Big <span class="math inline">\(\mathbf{Y}\)</span> and little <span class="math inline">\(\mathbf{y}\)</span> notation</h3>
<p>We distinguish between</p>
<ul>
<li><span class="math inline">\(\mathbf{Y}\)</span>: a vector of random variables, and</li>
<li><span class="math inline">\(\mathbf{y}\)</span>: a vector of constants, representing the observed value of <span class="math inline">\(\mathbf{Y}\)</span>.</li>
</ul>
<p>We can think of <span class="math inline">\(\mathbf{Y}\)</span> as corresponding to the period before the experiment has been conducted, when we don’t yet know what values we will observe, and <span class="math inline">\(\mathbf{y}\)</span> as corresponding to the period after the experiment has been conducted, after we have observed the values of the response variables.</p>
<p>In this module, we only ever consider the design of the experiment: we won’t actually obtain any data from any experiments we design, and so we will never have an observed <span class="math inline">\(\mathbf{y}\)</span> to work with.</p>
</section>
</section>
<section id="least-squares-estimation" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="least-squares-estimation"><span class="header-section-number">2.3</span> Least squares estimation</h2>
<p>We estimate <span class="math inline">\(\boldsymbol{\beta}\)</span> by minimising the sum of squares: we get an expression for the sum of squared errors, differentiate with respect to <span class="math inline">\(\boldsymbol{\beta}\)</span> and equate to zero. The least squares estimator is <span class="math display">\[\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T\mathbf{Y},\]</span> with the observed estimate obtain by replacing <span class="math inline">\(\mathbf{Y}\)</span> with <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>We won’t review the derivation of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> in this module, but for background reference, it is available <a href="https://oakleyj.github.io/MAS5052Part2/matrix-notation-for-linear-models.html#derivation-of-hatbeta">here</a>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Why this formula matters
</div>
</div>
<div class="callout-body-container callout-body">
<p>We won’t be calculating any numerical values of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> in this module but the formula is still important for two reasons:</p>
<ol type="1">
<li><p>a key task in experimental design is to choose the design matrix <span class="math inline">\(\mathbf{X}\)</span>; we can explore how the choice of <span class="math inline">\(\mathbf{X}\)</span> affects the statistical properties of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></p></li>
<li><p>the formula tells us we must choose <span class="math inline">\(\mathbf{X}\)</span> such that <span class="math inline">\((\mathbf{X}^T\mathbf{X})\)</span> is invertible.</p></li>
</ol>
</div>
</div>
<p>For <span class="math inline">\((\mathbf{X}^T\mathbf{X})\)</span> to be invertible <span class="math inline">\(\mathbf {X}\)</span> must be of <strong>full rank</strong> <span class="math inline">\(p\)</span> which, since <span class="math inline">\(\mathbf{X}\)</span> is an <span class="math inline">\(n\times p\)</span> matrix, requires <span class="math inline">\(n\geq p\)</span> (at least as many design points as parameters). If <span class="math inline">\(\mathbf{X}\)</span> is of full rank <span class="math inline">\(p\)</span> then <span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span> is a positive definite symmetric <span class="math inline">\(p\times p\)</span> matrix and is invertible. If it is not the case that <span class="math inline">\(\mathbf{X}\)</span> is of full rank, the model is said to be <strong>over-parametrised</strong>.</p>
</section>
<section id="statistical-properties-of-the-least-squares-estimator" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="statistical-properties-of-the-least-squares-estimator"><span class="header-section-number">2.4</span> Statistical properties of the least squares estimator</h2>
<p>We now consider the properties of <span class="math display">\[\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T\mathbf{Y},\]</span> noting that <span class="math inline">\(\mathbf{X}\)</span> is a constant and that <span class="math display">\[
\mathbf{Y}\sim N(\mathbf{X}\boldsymbol{\beta}, \sigma^2I_n)
\]</span> The least squares estimator is <em>unbiased</em>: <span class="math display">\[E(\hat{\boldsymbol{\beta}}) = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T\mathbf{X}\boldsymbol{\beta}=\boldsymbol{\beta}.\]</span></p>
<p>The variance-covariance matrix <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> of <span class="math inline">\(\boldsymbol{\beta}\)</span> is obtained as <span class="math display">\[\text{Var}(\hat{\boldsymbol{\beta}}) = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\sigma^2\mathbf{I}\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\]</span> which simplifies to <span class="math display">\[\text{Var}(\hat{\boldsymbol{\beta}}) =\sigma^2 (\mathbf{X}^T\mathbf{X})^{-1}\]</span> We can now state that <span class="math display">\[\hat{\boldsymbol{\beta}} \sim N(\boldsymbol{\beta}, \sigma^2  (\mathbf{X}^T\mathbf{X})^{-1}).\]</span> The matrix <span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span> is called the <strong>information matrix</strong> and is very relevant to the choice of design because, as seen above, it determines the accuracy of estimation of the parameters.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-2.3" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.4</strong></span> In the simple linear regression model, <span class="math inline">\(E(Y)=\beta_0+\beta_1x\)</span>, suppose one observation is taken at each of the points <span class="math inline">\(x_1, x_2, \ldots , x_n\)</span>. Then <span class="math display">\[\begin{align*}
\mathbf{X}^T\mathbf{X} &amp;= \left(\begin{array}{cc} n &amp; \sum_{j=1}^n x_j \\ \sum_{j=1}^n x_j &amp; \sum_{j=1}^n x_j^2 \end{array} \right) \\
&amp;=\left(\begin{array}{cc} n &amp; n\bar{x} \\ n\bar{x} &amp; s_{xx}+n\bar{x}^2 \end{array} \right)\\
(\mathbf{X}^T \mathbf{X})^{-1} &amp;=\frac{1}{ns_{xx}}\left( \begin{array}{cc} s_{xx}+n\bar{x}^2 &amp; -n\bar{x} \\
-n\bar{x} &amp; n \end{array} \right)
\end{align*}\]</span> where <span class="math inline">\(s_{xx}=\sum_{j=1}^{n}(x_j-\bar{x})^2=\sum_{j=1}^{n}x_j^2-n\bar{x}^2\)</span></p>
</div>
</div>
</div>
</section>
<section id="estimating-the-error-variance-sigma2" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="estimating-the-error-variance-sigma2"><span class="header-section-number">2.5</span> Estimating the error variance <span class="math inline">\(\sigma^2\)</span></h2>
<p>We can estimate <span class="math inline">\(\sigma^2\)</span> using the estimator <span class="math display">\[
\hat{\sigma}^2:=\frac{\hat{\boldsymbol{\varepsilon}}^T \hat{\boldsymbol{\varepsilon}}}{(n-p)}
\]</span> where <span class="math display">\[\hat{\boldsymbol{\varepsilon}}:= \mathbf{Y}-\hat{\mathbf{Y}}\]</span> is the vector of residuals, <span class="math display">\[
\hat{\mathbf{Y}} = \mathbf{HY},
\]</span> is the vector of fitted values, where the “hat matrix” <span class="math inline">\(\mathbf{H}\)</span> is defined as <span class="math display">\[
\mathbf{H}:=\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T
\]</span></p>
<p>and <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> are number of rows and columns respectively of <span class="math inline">\(\mathbf{X}\)</span>. This is an unbiased estimator of <span class="math inline">\(\sigma ^2\)</span> and is statistically independent of the estimator <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>Again, we won’t be computing estimates of <span class="math inline">\(\sigma^2\)</span> in this module; we’ll just note here that we require our experimental design to have <span class="math inline">\(n&gt;p\)</span> if we want to be able to estimate <span class="math inline">\(\sigma^2\)</span>.</p>
<p>It can also be shown that <span class="math inline">\(Var(\sigma^2)\)</span> decreases as <span class="math inline">\(n\)</span> increases, assuming <span class="math inline">\(p\)</span> is fixed, but it is not straightforward to make use of this result when choosing <span class="math inline">\(n\)</span>, so we will not consider this further.</p>
</section>
<section id="sec-qualvars" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="sec-qualvars"><span class="header-section-number">2.6</span> Models with qualitative variables</h2>
<p>Qualitative explanatory variables are usually called <strong>factor</strong> variables or <strong>categorical</strong> variables. For example, in an experiment to produce some chemical compound, suppose the explanatory variables are pressure <span class="math inline">\((x_1)\)</span> and temperature <span class="math inline">\((x_2)\)</span> and the effect of using one of two possible catalysts. The choice of catalyst would be a factor variable, and there are two ways of writing the linear model.</p>
<p>One way is to use an additional subscript to indicate the catalyst: we write <span class="math display">\[
E(Y_{ij}) = \alpha_i + \beta_1 x_{1, ij} + \beta_2x_{2,ij},
\]</span> where <span class="math inline">\(Y_{ij}\)</span> is the <span class="math inline">\(j\)</span>-th observation in which catalyst <span class="math inline">\(i\)</span> was used, for <span class="math inline">\(i=1,2\)</span>, and <span class="math inline">\(x_{1, ij}\)</span> and <span class="math inline">\(x_{2, ij}\)</span> are corresponding pressure and temperature respectively for this observation.</p>
<p>A second way to write such models is to use <strong>indicator</strong> variables to specify the level of the factor. A model which could be assumed is</p>
<p><span class="math display">\[E(Y_i) = \beta_0 + \alpha z_i + \beta_1x_{1,i} + \beta_2x_{2,i}\]</span></p>
<p>where <span class="math inline">\(z_i\)</span> is an indicator variable, taking the values, say, <span class="math inline">\(0\)</span> for the first catalyst and <span class="math inline">\(1\)</span> for the second catalyst. This model would be appropriate if the experimenter expects the relationship between the response and the factors temperature and pressure to be the same for both catalysts, except for a possible difference in level: the regression surfaces of <span class="math inline">\(y\)</span> against temperature (<span class="math inline">\(x_1\)</span>) and pressure (<span class="math inline">\(x_2\)</span>) for the two catalysts will be parallel, with the parameter <span class="math inline">\(\alpha\)</span> measuring the distance between them.</p>
<p>If three different catalysts are used, a possible model is <span class="math display">\[E(Y_i) = \beta_0 + \alpha_1z_{1,i} + \alpha_2z_{2,i}+ \alpha _3z_{3,i} + \beta_1x_{1,i} + \beta_2x_{2,i}\]</span> where <span class="math inline">\(z_{j,i}=1\)</span> if catalyst <span class="math inline">\(j\)</span> is used and <span class="math inline">\(z_i=0\)</span> otherwise. However, provided each run of the experiment uses one catalyst, this model is over-parametrised, because <span class="math inline">\(z_{1,i}+z_{2,i}+z_{3,i}=1\)</span>, and so the second, third and fourth columns of the design matrix add up to the first column, and <span class="math inline">\(X\)</span> is not of full rank. Another way of saying this is that <span class="math inline">\(\beta_0\)</span> is <strong>confounded</strong> with <span class="math inline">\(\alpha _1, \alpha _2\)</span> and <span class="math inline">\(\alpha _3\)</span>, in the sense that they cannot independently be estimated. Such an experiment cannot measure the <strong>absolute</strong> effects of the catalysts, but only the <strong>differences</strong> between their effects.</p>
<p>This over-parametrisation can be overcome by reducing the number of parameters by one, in various ways: for example, by removing <span class="math inline">\(\beta_0\)</span> from the model, or by imposing some linear constraint on the parameters <span class="math inline">\(\alpha _1, \alpha _2\)</span> and <span class="math inline">\(\alpha _3\)</span> so that one of them can be expressed in terms of the other two and eliminated from the model. If, for example, we impose the constraint <span class="math display">\[\alpha _1+\alpha _2+\alpha _3=0\]</span> then we may write <span class="math inline">\(\alpha _3=-\alpha _1-\alpha _2\)</span> and so eliminate <span class="math inline">\(\alpha _3\)</span> as a parameter of the model. Then <span class="math inline">\(\boldsymbol{\beta}= (\beta_0~~\alpha _1~~\alpha _2~~\beta_1~~\beta_2)^T\)</span> and for any design point <span class="math inline">\(\mathbf{x}\)</span> at which catalyst <span class="math inline">\(3\)</span> is used, <span class="math inline">\(\mathbf{f}(\mathbf{x})^T = (1~~-1~~-1~~x_1~~x_2 )\)</span>.</p>
</section>
<section id="sec-orthogonality" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="sec-orthogonality"><span class="header-section-number">2.7</span> Orthogonality</h2>
<p>Orthogonality is an important concept in experimental design, as orthogonal designs have desirable statistical properties.</p>
<p>Suppose that in a linear model <span class="math display">\[\boldsymbol{\beta}= \left( \begin{array}{c} \boldsymbol{\gamma}\\ \boldsymbol{\delta}\end{array}\right) \quad \text{and} \quad \mathbf{X}=(\mathbf {V} \quad \mathbf{W})\]</span> where, say, <span class="math inline">\(\boldsymbol{\gamma}\)</span> is a <span class="math inline">\(q\)</span>-vector, <span class="math inline">\(\boldsymbol{\delta}\)</span> is a <span class="math inline">\((p-q)\)</span>-vector, <span class="math inline">\(\mathbf{V}\)</span> is a <span class="math inline">\(n\times q\)</span> matrix and <span class="math inline">\(\mathbf{W}\)</span> is a <span class="math inline">\(n\times (p-q)\)</span> matrix; suppose further that every column of <span class="math inline">\(\mathbf{V}\)</span> is orthogonal (perpendicular) to every column of <span class="math inline">\(\mathbf{W}\)</span>, which may be written succinctly as <span class="math display">\[\mathbf{V}^T\mathbf{W}=\mathbf{0}.\]</span> Then the two groups of parameters comprising the components of <span class="math inline">\(\boldsymbol{\gamma}\)</span> and <span class="math inline">\(\boldsymbol{\delta}\)</span> are said to be <strong>orthogonal</strong> to each other.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Properties of orthogonal parameters
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>The estimators of orthogonal parameters are independent;</p></li>
<li><p>For two orthogonal parameters, the estimate of one does not change depending on whether or not the other is included in the model</p></li>
</ol>
</div>
</div>
<p>To understand the first property, note that <span class="math display">\[
\text{Var}(\hat{\boldsymbol{\beta}})=\left(\begin{array}{cc}\text{Var}(\hat{\boldsymbol{\gamma}}) &amp; \text{Cov}(\hat{\boldsymbol{\gamma}}, \hat{\boldsymbol{\delta}}) \\
\text{Cov}(\hat{\boldsymbol{\delta}}, \hat{\boldsymbol{\gamma}})&amp; \text{Var}(\hat{\boldsymbol{\delta}})
\end{array}\right)=\sigma ^2(\mathbf{X}^T\mathbf{X})^{-1}=\sigma ^2\left(\begin{array}{cc} (\mathbf{V}^T\mathbf{V})^{-1} &amp; \mathbf{0} \\ \mathbf{0} &amp; (\mathbf{W}^T\mathbf{W})^{-1} \end{array} \right).\]</span></p>
<p>In a multivariate normal distribution, zero correlation implies independence, so the estimators of <span class="math inline">\(\boldsymbol{\gamma}\)</span> and <span class="math inline">\(\boldsymbol{\delta}\)</span> are <em>independent</em> in the statistical sense.</p>
<p>To understand the second property, note that</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}} =  \left( \begin{array}{c} \hat{\boldsymbol{\gamma}}\\ \hat{\boldsymbol{\delta}}\end{array}\right) = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf Y = \left( \begin{array}{c} (\mathbf{V}^T\mathbf{V})^{-1}\mathbf{V}^T\mathbf Y\\ (\mathbf{W}^T\mathbf{W})^{-1}\mathbf{W}^T\mathbf Y\end{array}\right).
\]</span> If we were to remove the terms in the model corresponding to <span class="math inline">\(\boldsymbol{\delta}\)</span>, say, the design matrix would reduce to <span class="math inline">\(\mathbf{X} = \mathbf{V}\)</span> and we would have the same least squares estimate for <span class="math inline">\(\boldsymbol{\gamma}\)</span>. This can be desirable if, for example, the main interest is in estimating the <span class="math inline">\(\boldsymbol{\gamma}\)</span> parameters, but it is not straightforward to decide whether to include the <span class="math inline">\(\boldsymbol{\delta}\)</span> parameters or not: in this case the estimated <span class="math inline">\(\boldsymbol{\gamma}\)</span> would be the same either way.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-2.5" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.5</strong></span> The model <span class="math display">\[E(Y)=\beta_0+\alpha z+\beta_1x+\beta_{11}x^2\]</span> is proposed for which one observation is taken at each of the values <span class="math inline">\(x=-1,0,1\)</span> of the quantitative variable <span class="math inline">\(x\)</span> for each of the values <span class="math inline">\(z=-1,1\)</span> of the dummy variable <span class="math inline">\(z\)</span>. Investigate in this design which combinations of the four parameters of this model are mutually orthogonal. Ordering the parameters and the design points in an obvious way, we get <span class="math display">\[\mathbf{X}=\left( \begin{array}{cccc} 1 &amp; -1 &amp; -1 &amp; 1 \\ 1 &amp; -1 &amp; 0 &amp; 0 \\
1 &amp; -1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; -1 &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 1 \end{array} \right)\]</span> from which it follows taking sums of squares and products of columns that <span class="math display">\[\mathbf{X}^T\mathbf{X}=\left(\begin{array}{cccc} 6 &amp; 0 &amp; 0 &amp; 4 \\ 0 &amp; 6 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 4 &amp; 0 \\ 4 &amp; 0 &amp; 0 &amp; 4 \end{array} \right).\]</span> From this we can see that <span class="math inline">\(\{\beta_0, \beta_{11}\} ,\{\alpha\}\)</span> and <span class="math inline">\(\{\beta_1\}\)</span> are mutually orthogonal groups, but that <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_{11}\)</span> are not orthogonal to each other.</p>
</div>
</div>
</div>
<p>Note that it’s not sufficient for two column vectors of <span class="math inline">\(\mathbf{X}\)</span> to be orthogonal to each other for the corresponding parameters to be orthogonal: we need <span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span> to be <strong>block diagonal</strong>. To get a block diagonal matrix we may have to reorder the parameters in <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>Continuing <a href="#exm-2.5" class="quarto-xref">Example&nbsp;<span>2.5</span></a>, if we reorder the parameters and write: <span class="math display">\[\boldsymbol{\beta}= (\beta_0,\beta_{11}, \alpha, \beta_1)^T,\]</span> then corresponding to this reordered parameter vector we have <span class="math display">\[\mathbf{X}=\left( \begin{array}{cccc} 1 &amp; 1 &amp; -1 &amp; -1 \\ 1 &amp; 0&amp; -1 &amp; 0  \\
1 &amp; 1&amp; -1 &amp; 1  \\ 1 &amp; 1 &amp; 1 &amp; -1  \\ 1&amp; 0 &amp; 1 &amp; 0  \\ 1&amp; 1 &amp; 1 &amp; 1  \end{array} \right),\quad \mathbf{X}^T\mathbf{X}=\left(\begin{array}{cccc} 6 &amp; 4 &amp; 0 &amp; 0 \\ 4&amp; 4 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 6 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 4 \end{array} \right),\]</span> i.e.&nbsp;<span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span> is block diagonal.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-notortho" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.6</strong></span> Consider a model <span class="math display">\[
E(Y) = \beta_0 + \beta_1 x +\beta_2 z,
\]</span> with four observations at <span class="math inline">\((x,z)\)</span> pairs: <span class="math inline">\((1, 2), (2, -1), (3, -4), (3, 4)\)</span>. Writing the parameter vector as <span class="math inline">\(\boldsymbol{\beta}= (\beta_0,\beta_{1}, \beta_2)^T\)</span>, we have <span class="math display">\[
\mathbf{X}=\left( \begin{array}{ccc}1 &amp; 1 &amp; 2\\
1 &amp; 2 &amp; -1\\
1 &amp; 3 &amp; -4\\
1 &amp; 3 &amp; 4\end{array}\right),\quad \mathbf{X}^T\mathbf{X} =  \left( \begin{array}{ccc}
4 &amp; 9 &amp; -1\\
9 &amp; 23 &amp; 0\\
1 &amp; 0 &amp; 37\end{array}\right),\quad (\mathbf{X}^T\mathbf{X})^{-1} \simeq  \left( \begin{array}{rrr}2.22 &amp; -0.87 &amp; -0.06\\
-0.86 &amp; 0.38 &amp; 0.02\\
-0.05 &amp; 0.02 &amp; 0.03\end{array}\right)
\]</span> so even though the second and third columns of <span class="math inline">\(\mathbf{X}\)</span> are orthogonal (dot product is 0), the parameters <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are <strong>not</strong> orthogonal: their estimators are not independent, and removing one term from the model may change the estimate of the other.</p>
</div>
</div>
</div>
</section>
<section id="prediction" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="prediction"><span class="header-section-number">2.8</span> Prediction</h2>
<p>When designing an experiment, an objective may be to obtain suitable data for prediction: predicting the mean response at some point <span class="math inline">\(\mathbf{x_0}\)</span> in the design region which may or may not have been used in the design of the experiment. If we label this mean response as <span class="math inline">\(Y(\mathbf{x_0})\)</span>, then we have <span class="math display">\[Y(\mathbf{x_0})=\mathbf{f}(\mathbf{x_0})^T\boldsymbol{\beta}\]</span> The predicted value of the response at <span class="math inline">\(\mathbf{x_0}\)</span> is naturally estimated by <span class="math display">\[\hat{y}(\mathbf{x_0})=\mathbf{f}(\mathbf{x_0})^T\hat{\boldsymbol{\beta}}\]</span> which is unbiased and has variance given by <span class="math display">\[\begin{align}
\text{var}(\hat{Y}(\mathbf{x_0})) &amp;= \mathbf{f}(\mathbf{x_0})^T\text{Var}(\hat{\boldsymbol{\beta}})\mathbf{f}(\mathbf{x_0}) \\
&amp;=\sigma^2 \mathbf{f}(\mathbf{x_0})^T(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{f}(\mathbf{x_0}).
\end{align}\]</span> So the accuracy of prediction depends on the design matrix and also the point <span class="math inline">\(\mathbf{x_0}\)</span> chosen. R example 2.6 shows how prediction variance changes with choice of prediction point.</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-2.6" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.7</strong></span> In the simple linear regression model we have <span class="math display">\[(\mathbf{X}^T\mathbf{X})^{-1}=\frac{1}{ns_{xx}} \left( \begin{array}{cc} \sum x^2 &amp; -\sum x \\ -\sum x &amp; n \end{array} \right)\]</span> and so <span class="math display">\[\begin{align}
\text{var}(\hat{Y}(x_0)) &amp;= \text{var}(\hat{\beta_0}+\hat{\beta_1}x_0)\\
&amp;=\text{var} \left(\begin{array}{cc} 1 &amp; x_0 \end{array} \right)\left( \begin{array}{cc} \hat{\beta_0} &amp; \hat{\beta_1} \end{array} \right)^T\\
&amp;=\frac{\sigma^2}{ns_{xx}} \left( \begin{array}{cc} 1 &amp; x_0 \end{array} \right) \left( \begin{array}{cc} \sum x^2 &amp; -\sum x \\ -\sum x &amp; n \end{array} \right) \left( \begin{array}{c} 1 \\ x_0 \end{array} \right)\\
&amp;= \sigma ^2 \left( \frac{1}{n}+\frac{(x_0-\overline{x})^2}{s_{xx}} \right)
\end{align}\]</span> where <span class="math inline">\(\overline{x}=\sum x/n\)</span> and <span class="math inline">\(s_{xx} = \sum x^2 - n\overline{x}^2\)</span>. Some additional steps to help you understand this derivation are given in an Appendix (<a href="#sec-ch2Appendix" class="quarto-xref"><span>Section 2.11</span></a>).</p>
</div>
</div>
</div>
<p>Note that if a model fits well within a certain region in which the design points have been chosen, there is a danger in predicting outside this region, because there is no evidence that the model continues to fit well here, and there might be good scientific reason to believe that it does not. For example, a polynomial model which happens to fit well within a limited range might become wildly unrealistic outside it – say, predicting negative values in a situation where these are impossible.</p>
<p>For future purposes it is convenient here to introduce the <strong>standardised</strong> information matrix <span class="math display">\[\mathbf{M}=n^{-1} \mathbf{X}^T\mathbf{X}\]</span> and the <strong>standardised</strong> variance of prediction at a point <span class="math inline">\(\mathbf{x}\)</span> <span class="math display">\[d(\mathbf{x})=n\mathbf{f}(\mathbf{x})^T(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{f}(\mathbf{x})=\mathbf{f}(\mathbf{x})^T\mathbf{M}^{-1}\mathbf{f}(\mathbf{x})\]</span> where the inclusion of the factor <span class="math inline">\(n^{-1}\)</span> or <span class="math inline">\(n\)</span> compensates for the fact that increasing the sample size inevitably increases the accuracy of estimation, and the exclusion of the factor <span class="math inline">\(\sigma ^2\)</span> from <span class="math inline">\(d(\mathbf{x})\)</span> makes this function a dimensionless and more intrinsic feature of the design. For example, if a whole design is replicated then the standardised information matrix and variance of prediction are the same for the larger experiment as for the smaller one.</p>
</section>
<section id="sec-confregions" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="sec-confregions"><span class="header-section-number">2.9</span> Confidence regions</h2>
<p>We can obtain confidence intervals for individual parameters in a linear model, but we may be interested in the joint uncertainty of multiple parameters. In the previous section, we saw that the variance of a prediction depends on the variance-covariance <em>matrix</em> <span class="math inline">\(\text{Var}(\hat{\boldsymbol{\beta}})\)</span>. Hence we may want to consider confidence <em>regions</em> for the parameters jointly, as well as confidence intervals for individual parameters.</p>
<p>We will not prove this result here, but it can be shown that</p>
<p><span class="math display">\[p^{-1}\hat{\sigma}^{-2}(\hat{\boldsymbol{\beta}}-\boldsymbol{\beta})^T\mathbf{X}^T\mathbf{X}(\hat{\boldsymbol{\beta}}-\boldsymbol{\beta})\sim F_{p,n-p},\]</span><br>
provided <span class="math inline">\(n&gt;p\)</span>.</p>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence region for <span class="math inline">\(\boldsymbol{\beta}\)</span> will take the form <span class="math display">\[(\boldsymbol{\beta}-\hat{\boldsymbol{\beta}})^T\mathbf{X}^T\mathbf{X}(\boldsymbol{\beta}-\hat{\boldsymbol{\beta}}) \leq p\hat{\sigma}^2F_{p, n-p, 1-\alpha}\]</span> where <span class="math inline">\(F_{p, n-p, 1-\alpha}\)</span> is the <span class="math inline">\(100(1-\alpha)\)</span> percentile of the <span class="math inline">\(F_{n,p}\)</span> distribution.</p>
<p>It is not particularly helpful to <em>calculate</em> what the confidence region is, but the formula tells us how the confidence region relates to the choice of experimental design, through the design matrix <span class="math inline">\(\mathbf X\)</span>. Specifically, the confidence region will be the interior of an ellipsoid centred on <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>. Its size, shape and orientation depend on the covariance matrix <span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}\)</span>. The axes of the ellipsoid point in the directions given by the eigenvectors of <span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}\)</span>, and the length along each axis is proportional to the square root of the corresponding eigenvalue.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Volume of a confidence region
</div>
</div>
<div class="callout-body-container callout-body">
<p>Given that the confidence region is an ellipsoid, from properties of ellipsoids we can say that the volume of the confidence region will be proportional to <span class="math display">\[
\sqrt{|(\mathbf{X}^T\mathbf{X})^{-1}|}.
\]</span> Hence, when designing the experiment, the larger the determinant <span class="math inline">\(|\mathbf{X}^T\mathbf{X}|\)</span> is, the smaller we should expect the confidence region for <span class="math inline">\(\boldsymbol{\beta}\)</span> to be; the more accurate we should expect our estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span> to be.</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Example
</div>
</div>
<div class="callout-body-container callout-body">
<div id="exm-2.7" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.8</strong></span> Simple linear regression with observations taken at <span class="math inline">\(x=-1,0 \: \text{and}\: 1\)</span>, and <span class="math inline">\(\sigma^2\)</span> is unknown. In this case <span class="math display">\[\mathbf{X}^T\mathbf{X}= \left( \begin{array}{cc} 3 &amp; 0 \\ 0 &amp; 2 \end{array}\right)\]</span> and so the confidence region for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> is the interior of an ellipse <span class="math display">\[3(\beta_0-\hat{\beta_0})^2 + 2(\beta_1-\hat{\beta_1})^2 \leq 2\hat{\sigma}^2F_{2,1,1-\alpha }\]</span> where <span class="math inline">\(100(1-\alpha )\%\)</span> is the confidence level. In this case, <span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}\)</span> is diagonal, and has eigenvectors <span class="math inline">\((1,0)^T\)</span> and <span class="math inline">\((0,1)^T\)</span> and so the two parameters are orthogonal and the ellipse has its principal axes parallel to the co-ordinate axes.</p>
</div>
</div>
</div>
</section>
<section id="tasks" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="tasks"><span class="header-section-number">2.10</span> Tasks</h2>
<p>These questions will help you understand the matrix notation and revise some matrix algebra.</p>
<ol type="1">
<li><p>For the example discussed in <a href="#sec-qualvars" class="quarto-xref"><span>Section 2.6</span></a>, suppose there are two catalysts. For each catalyst, three observations are taken, with pressure and temperature settings <span class="math inline">\((p_1,t_1)\)</span>, <span class="math inline">\((p_2,t_2)\)</span> and <span class="math inline">\((p_3,t_3)\)</span>. Write down the design matrix for this experiment, assuming the indicator variable notation for the linear model.</p></li>
<li><p>If the <span class="math inline">\(i\)</span>th fitted value <span class="math inline">\(\hat{Y}_i\)</span> is defined as<br>
<span class="math display">\[
\hat{Y}_i= \mathbf{f}(\mathbf{x}_i)^T\hat{\boldsymbol{\beta}},
\]</span> check that the vector of fitted values <span class="math inline">\(\hat{\mathbf Y}\)</span> is given by <span class="math inline">\(\mathbf{HY}\)</span>.</p></li>
<li><p>First show that <span class="math display">\[\mathbf{H}^T\mathbf{H} = \mathbf{H},\]</span> assuming <span class="math inline">\((\mathbf{X}^T\mathbf{X})\)</span> is invertible. Then, by writing <span class="math inline">\(\hat{\mathbf Y}=\mathbf{HY}\)</span>, show that <span class="math display">\[\mathbf{Y}^T\mathbf{Y}=\hat{\mathbf{Y}}^T\hat{\mathbf{Y}}+\hat{\boldsymbol{\varepsilon}}^T\hat{\boldsymbol{\varepsilon}},\]</span> which is a decomposition of the sum of squares of the data into the sum of squares of the fitted values and the sum of squares of the residuals. These are called, respectively, the <strong>sum of squares due to the model</strong> and the <strong>residual (or error) sum of squares</strong>.</p></li>
<li><p>Consider the model and design in <a href="#exm-2.5" class="quarto-xref">Example&nbsp;<span>2.5</span></a>. A dataset corresponding to this design can be set up in R as follows (the <code>y</code> values are made up; the actual values are not important for this exercise).</p></li>
</ol>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>example2_5 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">z =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">y  =</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">9</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>By fitting suitable models in R, verify the second property of orthogonal parameters discussed in <a href="#sec-orthogonality" class="quarto-xref"><span>Section 2.7</span></a>.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Writing the parameter vector <span class="math inline">\(\boldsymbol{\beta}=(\beta_0, \alpha, \beta_1, \beta_2)^T\)</span>, we have <span class="math display">\[
\mathbf X = \left(\begin{array}{cccc}
1 &amp; 0 &amp; p_1 &amp; t_1\\
1 &amp; 0 &amp; p_2 &amp; t_2\\
1 &amp; 0 &amp; p_3 &amp; t_3\\
1 &amp; 1 &amp; p_1 &amp; t_1\\
1 &amp; 1 &amp; p_2 &amp; t_2\\
1 &amp; 1 &amp; p_3 &amp; t_3
\end{array}\right)
\]</span></p></li>
<li><p>We have <span class="math display">\[
\hat{\mathbf Y} =\left(\begin{array}{c}
\mathbf{f}(\mathbf{x}_1)^T\hat{\boldsymbol{\beta}}\\
\vdots \\
\mathbf{f}(\mathbf{x}_n)^T\hat{\boldsymbol{\beta}}
\end{array}\right) = \mathbf{X}\hat{\boldsymbol{\beta}} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y} = \mathbf{HY}
\]</span></p></li>
<li><p>Note that if <span class="math inline">\((\mathbf{X}^T\mathbf{X})\)</span> is invertible then <span class="math display">\[
((\mathbf{X}^T\mathbf{X})^{-1})^T = ((\mathbf{X}^T\mathbf{X})^T)^{-1} = (\mathbf{X}^T\mathbf{X})^{-1}.
\]</span>Then <span class="math display">\[
\mathbf{H}^T\mathbf{H}=\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T = \mathbf{H}.
\]</span> Hence <span class="math display">\[\begin{align}
\hat{\mathbf{Y}}^T\hat{\mathbf{Y}}+\hat{\boldsymbol{\varepsilon}}^T\hat{\boldsymbol{\varepsilon}} &amp;= (\mathbf{HY})^T\mathbf{HY}+(\mathbf{Y}-\mathbf{HY})^T(\mathbf{Y}-\mathbf{HY})\\
&amp;=\mathbf{Y}^T\mathbf{H}^T\mathbf{HY}+\mathbf{Y}^T\mathbf{Y}+\mathbf{Y}^T\mathbf{H}^T\mathbf{HY}-\mathbf{Y}^T\mathbf{H}\mathbf{Y}-\mathbf{Y}^T\mathbf{H}^T\mathbf{Y}\\
&amp;=\mathbf{Y}^T\mathbf{HY}+\mathbf{Y}^T\mathbf{Y}+\mathbf{Y}^T\mathbf{HY}-\mathbf{Y}^T\mathbf{H}\mathbf{Y}-\mathbf{Y}^T\mathbf{H}^T\mathbf{Y}\\
&amp;=\mathbf{Y}^T\mathbf{Y}
\end{align}\]</span> as required, as <span class="math inline">\(\mathbf{H}^T=\mathbf{H}\)</span>.</p></li>
<li><p>We fit the model specified in the example as follows:</p></li>
</ol>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> z <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>), example2_5)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x + z + I(x^2), data = example2_5)

Coefficients:
(Intercept)            x            z       I(x^2)  
      6.500        2.250       -2.333        1.750  </code></pre>
</div>
</div>
<p>It was noted that <span class="math inline">\(\{\beta_0, \beta_{11}\} ,\{\alpha\}\)</span> and <span class="math inline">\(\{\beta_1\}\)</span> are mutually orthogonal groups. If we remove the terms in the model corresponding to one group, the remaining parameter estimates should not change. We verify this as follows:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> x  <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>), example2_5) <span class="co"># remove z</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x + I(x^2), data = example2_5)

Coefficients:
(Intercept)            x       I(x^2)  
       6.50         2.25         1.75  </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> z <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>), example2_5) <span class="co"># remove x</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ z + I(x^2), data = example2_5)

Coefficients:
(Intercept)            z       I(x^2)  
      6.500       -2.333        1.750  </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> z <span class="sc">-</span> <span class="dv">1</span>, example2_5) <span class="co"># remove the intercept and x^2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x + z - 1, data = example2_5)

Coefficients:
     x       z  
 2.250  -2.333  </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-ch2Appendix" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="sec-ch2Appendix"><span class="header-section-number">2.11</span> Appendix</h2>
<p>Some results to help with the algebra in this section. First note that we can write <span class="math inline">\(\sum_{i=1}^n x_i = n\bar{x}\)</span>. Then</p>
<p><span class="math display">\[\begin{align}
s_{xx}&amp;:= \sum_{i=1}^n (x_i -\bar{x}^2)\\
&amp;= \left(\sum_{i=1}^n x_i^2\right) - 2\bar{x}\left(\sum_{i=1}^nx_i\right) + \left(\sum_{i=1}^n \bar{x}^2\right)\\
&amp; = \left(\sum_{i=1}^n x_i^2\right) - 2\bar{x}n\bar{x} + n\bar{x}^2\\
&amp; = \left(\sum_{i=1}^n x_i^2\right) - n\bar{x}^2.
\end{align}\]</span></p>
<p>To help with <a href="#exm-2.6" class="quarto-xref">Example&nbsp;<span>2.7</span></a>, we can use the result above to write <span class="math display">\[
\sum_{i=1}^n x_i^2 = s_{xx} + n\bar{x}^2
\]</span> Then we have <span class="math display">\[\begin{align}
\left( \begin{array}{cc} 1 &amp; x_0 \end{array} \right) \left( \begin{array}{cc} \sum_{i=1}^n x^2 &amp; -\sum_{i=1}^n x \\ -\sum_{i=1}^n x &amp; n \end{array} \right) \left( \begin{array}{c} 1 \\ x_0 \end{array} \right)&amp;= \left( \begin{array}{cc} 1 &amp; x_0 \end{array} \right) \left( \begin{array}{cc} \sum_{i=1}^n x^2 &amp; -n\bar{x} \\ -n\bar{x} &amp; n \end{array} \right) \left( \begin{array}{c} 1 \\ x_0 \end{array} \right)\\&amp;=\sum_{i=1}^n x_i^2 - 2nx_0\bar{x} + nx_0^2\\
&amp;= s_{xx} +n\bar{x}^2 - 2nx_0\bar{x} + nx_0^2\\
&amp;= s_{xx} + n (x_0-\bar{x})^2,
\end{align}\]</span> from which we derive the expression for <span class="math inline">\(\text{var}(\hat{Y}(x_0))\)</span>.</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>If you’ve forgotten the definition/properties of variance-covariance matrices, some notes are available here: <a href="https://oakleyj.github.io/MAS61004LM/randomVectors.html#covariance-matrix">https://oakleyj.github.io/MAS61004LM/randomVectors.html#covariance-matrix</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Introduction to experimental design.html" class="pagination-link" aria-label="Introduction to Experimental Design">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Experimental Design</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Optimality.html" class="pagination-link" aria-label="Optimality criteria">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Optimality criteria</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>